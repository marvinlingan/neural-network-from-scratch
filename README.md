# ðŸ§  Neural Network From Scratch

Building a full feedforward neural network using Python & NumPy â€” from forward pass to loss calculation â€” without any high-level ML frameworks.

## ðŸ› ï¸ What Iâ€™m Implementing
- Dense Layers
- Activation Functions (ReLU, Softmax)
- Loss Functions (Categorical Cross-Entropy)
- Full Forward Pass
- Accuracy & Loss Visualization

## ðŸš§ Why Iâ€™m Building This
To deeply understand how neural networks work under the hood â€” every matrix multiply, every gradient, every byte of logic.

## ðŸ“Œ Stay Tuned
This is an active project! Iâ€™ll be uploading code, adding notebooks, and breaking down each concept in detail.

> Follow along on [Twitter](https://twitter.com/MarvLing20) or [LinkedIn](https://linkedin.com/in/marvin-lingan).
