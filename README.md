# 🧠 Neural Network From Scratch

Building a full feedforward neural network using Python & NumPy — from forward pass to loss calculation — without any high-level ML frameworks.

## 🛠️ What I’m Implementing
- Dense Layers
- Activation Functions (ReLU, Softmax)
- Loss Functions (Categorical Cross-Entropy)
- Full Forward Pass
- Accuracy & Loss Visualization

## 🚧 Why I’m Building This
To deeply understand how neural networks work under the hood — every matrix multiply, every gradient, every byte of logic.

## 📌 Stay Tuned
This is an active project! I’ll be uploading code, adding notebooks, and breaking down each concept in detail.

> Follow along on [Twitter](https://twitter.com/MarvLing20) or [LinkedIn](https://linkedin.com/in/marvin-lingan).
